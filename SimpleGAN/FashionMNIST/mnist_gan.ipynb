{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e3ec95",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mvutils\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd2f872",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchaudio'"
     ]
    }
   ],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f8bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(nz, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1, 28, 28)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input.view(-1, 28*28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627a7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "nz = 100  # Size of z latent vector (i.e. size of generator input)\n",
    "lr = 0.0002  # Learning rate\n",
    "batch_size = 128  # Batch size\n",
    "epochs = 100  # Number of training epochs\n",
    "\n",
    "# Initialize the networks\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "netG = Generator(nz).to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Fixed noise for generating images for visualization\n",
    "fixed_noise = torch.randn(64, nz, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for i, (data, _) in enumerate(dataloader):\n",
    "        # Update Discriminator\n",
    "        netD.zero_grad()\n",
    "        real_data = data.to(device)\n",
    "        batch_size = real_data.size(0)\n",
    "        label = torch.full((batch_size,), 1., dtype=torch.float, device=device)\n",
    "        \n",
    "        output = netD(real_data).view(-1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        \n",
    "        noise = torch.randn(batch_size, nz, device=device)\n",
    "        fake_data = netG(noise)\n",
    "        label.fill_(0.)\n",
    "        \n",
    "        output = netD(fake_data.detach()).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Update Generator\n",
    "        netG.zero_grad()\n",
    "        label.fill_(1.)  # Reuse labels for generator loss\n",
    "        \n",
    "        output = netD(fake_data).view(-1)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Print and save losses\n",
    "        if i % 100 == 0:\n",
    "            print(f'[{epoch}/{epochs}][{i}/{len(dataloader)}] Loss_D: {errD_real.item() + errD_fake.item()} Loss_G: {errG.item()}')\n",
    "\n",
    "    # Generate images for visualization and save\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake_images = netG(fixed_noise).detach().cpu()\n",
    "        \n",
    "        # Denormalize images\n",
    "        fake_images = fake_images * 0.5 + 0.5\n",
    "        \n",
    "        # Save images\n",
    "        vutils.save_image(fake_images, f'gan_images_epoch_{epoch}.png', nrow=8, normalize=True)\n",
    "\n",
    "print(\"Training finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_generated_images(netG, num_images=64):\n",
    "    \"\"\"\n",
    "    Plots the output of the generator.\n",
    "\n",
    "    Args:\n",
    "        netG: The generator network.\n",
    "        num_images: Number of images to generate and plot.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_images, nz, device=device)\n",
    "        fake_images = netG(noise).detach().cpu()\n",
    "\n",
    "    # Denormalize images\n",
    "    fake_images = fake_images * 0.5 + 0.5\n",
    "\n",
    "    # Plot images\n",
    "    fig, axs = plt.subplots(8, 8, figsize=(8, 8))\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        ax.imshow(fake_images[i].squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
